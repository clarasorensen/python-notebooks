{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Feature Representations of MNIST digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load(filename):\n",
    "    Xy = np.loadtxt(filename, delimiter=',')\n",
    "    y = Xy[:, -1]\n",
    "    X = Xy[:, :-1]\n",
    "    return X, y\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "def knn_predscore(trainX, trainy, testX, testy, k, metric='euclidean'):\n",
    "    model = KNeighborsClassifier(n_neighbors=k,\n",
    "                                metric=metric)\n",
    "\n",
    "    model.fit(trainX, trainy)\n",
    "    return model.score(testX, testy)\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "def perceptron_predscore(trainX, trainy, testX, testy):\n",
    "    model = Perceptron(n_iter=200)\n",
    "    model.fit(trainX, trainy)\n",
    "    return model.score(testX, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the MNIST images as 784-dimensional vectors (each dim a pixel) as in PS1. Keep only the 9s and 4s -- binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainXraw, trainyraw = load('training.txt')\n",
    "testXraw, testyraw = load('testing.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c1 = 7\n",
    "c2 = 9\n",
    "trainX = trainXraw[(trainyraw == c1) | (trainyraw == c2), :]\n",
    "trainy = trainyraw[(trainyraw == c1) | (trainyraw == c2)]\n",
    "\n",
    "testX = testXraw[(testyraw == c1) | (testyraw == c2), :]\n",
    "testy = testyraw[(testyraw == c1) | (testyraw == c2)]\n",
    "\n",
    "print 'Loaded', trainy.size, 'training points and', testy.size, 'testing points'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'kNN accuracy on original feature rep is', knn_predscore(trainX, trainy, testX, testy, 3)\n",
    "print 'Perceptron accuracy on original feature rep is', perceptron_predscore(trainX, trainy, testX, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tangent: Visualizing w\n",
    "\n",
    "The weight vector learned by the perceptron to distinguish 7 and 9 is itself a 784-dim vector, since the data lives in 784 dimensions. Just for fun, let us visualize it as an image!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from numpy.linalg import norm\n",
    "\n",
    "model = Perceptron(n_iter=200, fit_intercept=False)\n",
    "model.fit(trainX, trainy)\n",
    "w = model.coef_[0]\n",
    "w/=norm(w, 2)\n",
    "\n",
    "plt.imshow(w.reshape(28, 28), interpolation='none', cmap = plt.get_cmap('jet'), \n",
    "           vmin = np.min(w), vmax = np.max(w))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: Center and Variance-Scale the Features\n",
    "\n",
    "### 1a\n",
    "\n",
    "Compute the mean for each of the 784 features.\n",
    "Center the points by subtracting the mean.\n",
    "\n",
    "$$f_{i, j}-\\mu_j$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "meanimg = np.mean(trainX, axis=0)  # get mean of each feature\n",
    "# visualize mean image for fun\n",
    "plt.imshow(meanimg.reshape(28, 28), interpolation='none', cmap = plt.get_cmap('gray'), vmin = 0, vmax = 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "centeredTrainX = trainX-meanimg\n",
    "centeredTestX = testX-meanimg # can't use means of test data; use training means\n",
    "    \n",
    "print 'kNN accuracy on centered feature rep is', knn_predscore(centeredTrainX, trainy, centeredTestX, testy, 3)\n",
    "print 'Perceptron accuracy on centered feature rep is', perceptron_predscore(centeredTrainX, trainy, centeredTestX, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b\n",
    "\n",
    "Compute the standard deviation for each of the features and normalize each vector.\n",
    "\n",
    "$$\\dfrac{f_{i, j}}{\\sigma_j}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stds = np.std(trainX, axis=0)  # get variance on each column (feature)\n",
    "stds[stds==0] = 1  # to prevent zero division errors\n",
    "stdnormTrainX = trainX/stds\n",
    "stdnormTestX = testX/stds # can't use variances of test data; use training variances\n",
    "\n",
    "print 'kNN accuracy on normalized feature rep is', knn_predscore(stdnormTrainX, trainy, stdnormTestX, testy, 3)\n",
    "print 'Perceptron accuracy on normalized feature rep is', perceptron_predscore(stdnormTrainX, trainy, stdnormTestX, testy)\n",
    "\n",
    "censtdnormTrainX = centeredTrainX/stds\n",
    "censtdnormTestX = centeredTestX/stds\n",
    "print 'kNN accuracy on centered+normalized feature rep is', knn_predscore(censtdnormTrainX, trainy, censtdnormTestX, testy, 3)\n",
    "print 'Perceptron accuracy on centered+normalized feature rep is', perceptron_predscore(censtdnormTrainX, trainy, censtdnormTestX, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Example-Norm the Data-Points\n",
    "\n",
    "Scale every data-point (row) by its Euclidean norm.\n",
    "\n",
    "$$\\dfrac{x}{||x||}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainnorms = norm(trainX, axis=1, keepdims=True)\n",
    "exnormTrainX = trainX/trainnorms\n",
    "testnorms = norm(testX, axis=1, keepdims=True)\n",
    "exnormTestX = testX/testnorms\n",
    "print 'kNN accuracy on example-normed feature rep is', knn_predscore(exnormTrainX, trainy, exnormTestX, testy, 3)\n",
    "print 'Perceptron accuracy on example-normed feature rep is', perceptron_predscore(exnormTrainX, trainy, exnormTestX, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: Simpler Feature Design\n",
    "\n",
    "### Binarize the Feature Values\n",
    "\n",
    "Make every feature value 0 or 1 by thresholding (remove grays)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binTrainX = np.zeros(trainX.shape)\n",
    "binTrainX[trainX>50] = 1\n",
    "binTestX = np.zeros(testX.shape)\n",
    "binTestX[testX>50] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'kNN accuracy on binarized feature rep is', knn_predscore(binTrainX, trainy, binTestX, testy, 3)\n",
    "print 'Perceptron accuracy on binarized feature rep is', perceptron_predscore(binTrainX, trainy, binTestX, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Region-Based Feature Representations\n",
    "\n",
    "Here's one simple way of featurizing the image with a small number of dimensions.\n",
    "\n",
    "Re-represent the data points as n-dimensional vectors consisting of the number of black pixels in n regions of the image.\n",
    "\n",
    "Does this give us enough information for classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def numblack(X, regions):\n",
    "    Xregions = []\n",
    "    dims = X.shape[1]\n",
    "    for i in range(regions):\n",
    "        if i==0:\n",
    "            tmp = X[:, :dims/regions]\n",
    "        else:\n",
    "            tmp = X[:, dims*(i-1)/regions:dims*i/regions]\n",
    "        Xregions.append(np.sum(tmp==0, axis=1))\n",
    "    return np.vstack(tuple(Xregions)).T\n",
    "    \n",
    "blackTestX = numblack(testX, 28)\n",
    "blackTrainX = numblack(trainX, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'kNN accuracy on 1-dim feature rep is', sklearn_knn_predictscore(blackTrainX, trainy, blackTestX, testy, 3, 'euclidean')\n",
    "print 'Perceptron accuracy on 1-dim feature rep is', perceptron_predscore(blackTrainX, trainy, blackTestX, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
